{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_1 = pd.read_csv('Data/DatasetOne.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop columns with only nulls\n",
    "null_col_bool = [i for i in [data_1.isna().sum() != len(data_1)][0]]\n",
    "cols_keep = data_1.columns[null_col_bool]\n",
    "data_1 = data_1.loc[:, cols_keep]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop this columns because all values are zero (these are related to Instagram and Linkedin attributes, and we ont have Instagram or Linknedin data)\n",
    "cols_drop = [col for col in data_1.select_dtypes(include=['int', 'float']) if data_1[col].sum() == 0]\n",
    "data_1.drop(columns = cols_drop, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Drop columns because all entries are 0\n",
    "0 == data_1['Is Syndicated'].sum() == data_1['Linkedin Sponsored'].sum() == data_1['Starred'].sum() == data_1['Checked'].sum()\n",
    "\n",
    "# Drop columns becuase they only have one unique value (True for example)\n",
    "1 == data_1['Total Monthly Visitors'].nunique() == data_1['Content Source'].nunique() == data_1['Content Source Name'].nunique() == data_1['Page Type Name'].nunique() == data_1['Pub Type'].nunique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       " 0.000000      447157\n",
       "-77.036819          3\n",
       "-87.629005          2\n",
       "-78.534470          1\n",
       "-84.772171          1\n",
       "-75.708061          1\n",
       "-74.011040          1\n",
       "-80.546501          1\n",
       "-87.628670          1\n",
       "-87.630859          1\n",
       "-79.926163          1\n",
       "-121.919281         1\n",
       "-118.100418         1\n",
       "-115.148445         1\n",
       "Name: Longitude, dtype: int64"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Not very useful, same case with Latitude\n",
    "data_1['Longitude'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Non useful columns \n",
    "non_useful_cols = ['Avatar', 'Latitude', 'Longitude', 'Total Monthly Visitors', 'Content Source', 'Is Syndicated', 'Linkedin Sponsored', 'Starred', 'Content Source Name', 'Page Type Name', 'Pub Type', 'Checked']\n",
    "data_1.drop(columns = non_useful_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_2 = pd.read_csv('Data/DatasetTwo.csv')\n",
    "data_2 = data_2.loc[:, cols_keep]\n",
    "data_2.drop(columns = cols_drop, inplace=True)\n",
    "data_2.drop(columns = non_useful_cols, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code', 'Continent Code', 'Continent',\n",
       "       'Country', 'City Code', 'Account Type', 'Added', 'Author', 'City',\n",
       "       'Entity Info', 'Expanded URLs', 'Full Name', 'Full Text', 'Gender',\n",
       "       'Hashtags', 'Impact', 'Impressions', 'Interest', 'Location Name',\n",
       "       'Media URLs', 'Mentioned Authors', 'Original Url', 'Professions',\n",
       "       'Resource Id', 'Short URLs', 'Thread Author', 'Thread Created Date',\n",
       "       'Thread Entry Type', 'Thread Id', 'Twitter Author ID',\n",
       "       'Twitter Followers', 'Twitter Following', 'Twitter Reply Count',\n",
       "       'Twitter Reply to', 'Twitter Retweet of', 'Twitter Retweets',\n",
       "       'Twitter Likes', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Reach (new)', 'Engagement Type', 'Region', 'Region Code',\n",
       "       'Weblog Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Final columns kept\n",
    "data_1.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code', 'Continent Code', 'Continent',\n",
       "       'Country', 'City Code', 'Account Type', 'Added', 'Author', 'City',\n",
       "       'Entity Info', 'Expanded URLs', 'Full Name', 'Full Text', 'Gender',\n",
       "       'Hashtags', 'Impact', 'Impressions', 'Interest', 'Location Name',\n",
       "       'Media URLs', 'Mentioned Authors', 'Original Url', 'Professions',\n",
       "       'Resource Id', 'Short URLs', 'Thread Author', 'Thread Created Date',\n",
       "       'Thread Entry Type', 'Thread Id', 'Twitter Author ID',\n",
       "       'Twitter Followers', 'Twitter Following', 'Twitter Reply Count',\n",
       "       'Twitter Reply to', 'Twitter Retweet of', 'Twitter Retweets',\n",
       "       'Twitter Likes', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Reach (new)', 'Engagement Type', 'Region', 'Region Code',\n",
       "       'Weblog Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{profession=Artist, jobTitle=Artist}                                                                                                                                    3348\n",
       "{profession=Teacher & Lecturer, jobTitle=Teacher}                                                                                                                       2398\n",
       "{profession=Executive, jobTitle=Owner}                                                                                                                                  1704\n",
       "{profession=Health practitioner, jobTitle=Vet}                                                                                                                          1669\n",
       "{profession=Executive, jobTitle=President}                                                                                                                              1536\n",
       "                                                                                                                                                                        ... \n",
       "{profession=Artist, jobTitle=Photographer}, {profession=Artist, jobTitle=Urban Planner}                                                                                    1\n",
       "{profession=Artist, jobTitle=Songwriter}, {profession=Teacher & Lecturer, jobTitle=Teacher}                                                                                1\n",
       "{profession=Artist, jobTitle=Composer}, {profession=Journalist, jobTitle=Editor}, {profession=Executive, jobTitle=Founder}, {profession=Artist, jobTitle=Songwriter}       1\n",
       "{profession=Health practitioner, jobTitle=Counselor}, {profession=Health practitioner, jobTitle=Psychoanalyst}                                                             1\n",
       "{profession=Artist, jobTitle=Artist}, {profession=Scientist & Researcher, jobTitle=Neuroscientist}                                                                         1\n",
       "Name: Professions, Length: 3592, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['Professions'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "422985"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['Engagement Type'].value_counts().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "391422"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.Title.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "55751"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_1) - data_1.Title.duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False    439974\n",
       "True       7199\n",
       "Name: Twitter Verified, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1['Twitter Verified'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Twitter Verified\n",
       "False    226703\n",
       "True     206244\n",
       "Name: Twitter Retweets, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_1.groupby('Twitter Verified')['Twitter Retweets'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12        RT @nicksortor ðŸš¨ #BREAKING: The State of Ohio ...\n",
       "16        RT @OccupyDemocrats BREAKING: The state of Ohi...\n",
       "17        RT @ACTBrigitte Immediately after the train cr...\n",
       "27        RT @CTVNews Ohio sues Norfolk Southern over to...\n",
       "29        RT @TristanSnell Get rid of train safety rules...\n",
       "                                ...                        \n",
       "366925    RT @bennyjohnson Has Joe Biden said anything a...\n",
       "366926    RT @CRRJA5 Ohio Chernobyl ðŸ¥µand we havenâ€™t hear...\n",
       "366927    RT @CL4WS_OUT This video shows a fiery axle on...\n",
       "366928    RT @KanekoaTheGreat THREAD: Photos, videos, an...\n",
       "366929    RT @prem_thakker I spoke with the people of Ea...\n",
       "Name: Title, Length: 310497, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_2.Title[data_2.Title.duplicated()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tweets from data_1 and data_2\n",
    "data_3 = pd.concat([data_2, data_1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(814103, 753791, 814102)"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_3), data_3.Title.duplicated().sum(), data_3['Query Id'].duplicated().sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code', 'Continent Code', 'Continent',\n",
       "       'Country', 'City Code', 'Account Type', 'Added', 'Author', 'City',\n",
       "       'Entity Info', 'Expanded URLs', 'Full Name', 'Full Text', 'Gender',\n",
       "       'Hashtags', 'Impact', 'Impressions', 'Interest', 'Location Name',\n",
       "       'Media URLs', 'Mentioned Authors', 'Original Url', 'Professions',\n",
       "       'Resource Id', 'Short URLs', 'Thread Author', 'Thread Created Date',\n",
       "       'Thread Entry Type', 'Thread Id', 'Twitter Author ID',\n",
       "       'Twitter Followers', 'Twitter Following', 'Twitter Reply Count',\n",
       "       'Twitter Reply to', 'Twitter Retweet of', 'Twitter Retweets',\n",
       "       'Twitter Likes', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Reach (new)', 'Engagement Type', 'Region', 'Region Code',\n",
       "       'Weblog Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3.drop_duplicates(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_3.drop_duplicates(subset = ['Title'], inplace=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60312"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(data_3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "NaN        26329\n",
       "RETWEET    20744\n",
       "REPLY      10670\n",
       "QUOTE       2569\n",
       "Name: Engagement Type, dtype: int64"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3['Engagement Type'].value_counts(dropna=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "5111"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_3['Twitter Verified'] == True).sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24             WashTimes\n",
       "28             dansewell\n",
       "33                  ksbw\n",
       "35        SenJeffMerkley\n",
       "47               CTVNews\n",
       "               ...      \n",
       "444234    JordanChariton\n",
       "446547           FoxNews\n",
       "446934     MorePerfectUS\n",
       "446939    JosephWulfsohn\n",
       "446958     microsoftnews\n",
       "Name: Author, Length: 5111, dtype: object"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3['Author'][data_3['Twitter Verified'] == True]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'{profession=Journalist, jobTitle=Editor}, {profession=Teacher & Lecturer, jobTitle=Teacher}'"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(data_3['Professions'][data_3['Twitter Verified'] == True].iloc[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "24                                                        0\n",
       "28        {profession=Journalist, jobTitle=Editor}, {pro...\n",
       "33                                                        0\n",
       "35                {profession=Politician, jobTitle=Senator}\n",
       "47                                                        0\n",
       "                                ...                        \n",
       "444234         {profession=Journalist, jobTitle=Journalist}\n",
       "446547                                                    0\n",
       "446934                                                    0\n",
       "446939           {profession=Journalist, jobTitle=Reporter}\n",
       "446958                                                    0\n",
       "Name: Professions, Length: 5111, dtype: object"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3['Professions'][data_3['Twitter Verified'] == True].apply(lambda x: 0 if x is np.nan else x)\n",
    "# journalist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True     0.996638\n",
       "False    0.003362\n",
       "Name: Professions, dtype: float64"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Organizations accounts do not have professions, so we cannot use that to get news media organizations\n",
    "data_3['Professions'][(data_3['Account Type'] == 'organisational') & (data_3['Twitter Verified'] == True)].isna().value_counts(normalize=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "potential_news_org = [i for i in data_3['Author'][(data_3['Account Type'] == 'organisational') & (data_3['Twitter Verified'] == True)].value_counts().index]"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## To do\n",
    "Create a list of media accounts to match with the other data set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_verified = [i for i in data_3['Author'][(data_3['Account Type'] == 'individual') & (data_3['Twitter Verified'] == True)].value_counts().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "count = 0\n",
    "news_org_list = []\n",
    "check_by_hand = []\n",
    "pattern = re.compile(r'news|abc|cnn|cbs|reuters|AP|times|fox|post|nbc|cnbc|bloomberg|gazette|hours|politico|cspan|politics|msn|journal|Tribune|daily|wsj|yahoo|tv|sun|time|radio|chronicle|herald|today', re.IGNORECASE) \n",
    "for item in potential_news_org:\n",
    "    if pattern.search(item):\n",
    "        news_org_list.append(item)\n",
    "    else:\n",
    "        check_by_hand.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "# MK NEWS ACCOUNTS\n",
    "mk_news_org = pd.read_csv('MK/news_accounts_dataset3.csv')\n",
    "mk_news_org = mk_news_org.SENDER.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_orgs_list2 = []\n",
    "check_by_hand_2 = []\n",
    "for account in check_by_hand:\n",
    "    if account in mk_news_org:\n",
    "      news_orgs_list2.append(account)\n",
    "    else:\n",
    "       check_by_hand_2.append(account)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "political = []\n",
    "check_by_hand_3 = []\n",
    "pattern = re.compile(r'GOP|Gov|Senate|Senator|Rep', re.IGNORECASE) \n",
    "for item in check_by_hand_2:\n",
    "    if pattern.search(item):\n",
    "        political.append(item)\n",
    "    else:\n",
    "        check_by_hand_3.append(item)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "political + ['RudyGiuliani', 'USDOT', 'ChineseEmbinHU', 'TeamCavuto', 'TheDemCoalition', 'Ohio_OCJS', 'SenSchumer', 'FEMAregion3', 'EPAregion3', 'FDA_ORA']\n",
    "activists = ['PghProtests', 'CleanAirMoms', 'POGOwatchdog', 'genzforchange', 'PatrioticMills', 'TheUSASingers', 'OhioFarmBureau', 'gofundme', 'RevJJackson', 'AAF']\n",
    "other = ['RedCross', 'scifri', 'AmChemistry', 'RedCrossNOH', 'GoyaFoods']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_orgs_list3 = [i for i in check_by_hand_3 if i not in (political + activists + other)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_org = news_org_list + news_orgs_list2 + news_orgs_list3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_org = list(set(news_org))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now, from all other accounts (non organizational , verified):"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_verified = [i for i in data_3['Author'][(data_3['Account Type'] == 'individual') & (data_3['Twitter Verified'] == True)].value_counts().index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1266"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(individual_verified)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "individual_verified = [i for i in individual_verified if i not in (news_org + political + activists + other)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "count = 0\n",
    "news_ind_list = []\n",
    "check_by_hand_ind = []\n",
    "pattern = re.compile(r'news|abc|cnn|cbs|reuters|AP|times|fox|post|nbc|cnbc|bloomberg|chron|gazette|hours|politico|cspan|politics|msn|journal|Tribune|daily|wsj|yahoo|tv|sun|time|radio|chronicle|herald|today', re.IGNORECASE) \n",
    "for item in individual_verified:\n",
    "    if pattern.search(item):\n",
    "        news_ind_list.append(item)\n",
    "    else:\n",
    "        check_by_hand_ind.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "214"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(news_ind_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "news = news_org + news_ind_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1052"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_by_hand_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "political_ind = []\n",
    "check_by_hand_ind2 = []\n",
    "pattern = re.compile(r'GOP|Gov|Senate|Senator|Rep|Sen|EPA', re.IGNORECASE) \n",
    "for item in check_by_hand_ind:\n",
    "    if pattern.search(item):\n",
    "        political_ind.append(item)\n",
    "    else:\n",
    "        check_by_hand_ind2.append(item)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(political_ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "politics = political + political_ind"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Here, Im reading MK classification final!!\n",
    "MK_byhand = pd.read_csv('check_by_hand_cleanMK.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "MK_byhand.set_index('check_by_hand_ind2', inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "MK_byhand.fillna(0, inplace=True)\n",
    "news_org_additional = MK_byhand.query('news == 1').index.to_list()\n",
    "government_additional = MK_byhand.query('political == 1').index.to_list()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# news_org_additional"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I am having a hard time classifying these guys: these are verified individual accounts, some are media, some are journalists (so, also media), but some are politicians, some are people\n",
    "# check_by_hand_ind2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "986"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(check_by_hand_ind2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "896"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "check_by_hand_ind3 = [i for i in check_by_hand_ind2 if i not in (news_org_additional+government_additional)]\n",
    "len(check_by_hand_ind3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "people = ['RobertKennedyJr', '_SemaHernandez_', 'CatoInstitute', 'ColMorrisDavis', 'mrtgr', 'LindseyBoylan', 'AJPennyfarthing', 'DrEricDing', 'mattkbh', 'AlBernstein', 'lootpress', 'DinahVP', 'iskandrah'\\\n",
    "          '_Zeets', 'vickorano', 'addedvalueth', 'IBDinvestors', 'SierraClub', 'StephenJ_Caruso', 'djrelentt', 'ErickFernandez', 'ceciliakcecilia', 'michaelmalice', 'court_bennett11'\\\n",
    "            'MsAConner', 'BrookingsEcon', 'MeredithLClark', 'drdavidmichaels', 'AWCities', 'laurenpeikoff', 'WajahatAli', 'MarkRuffalo', 'NewEconomics', 'EricMGarcia', 'GooRee']\n",
    "political = ['TPPatriots', 'PalimenoForGAD1', 'ForTexasHoujami', 'ProgressOhio', 'mh4oh', 'ElectMattDolan', 'Mike_Pence', 'Heritage', 'NorthCarolinaGP', 'HCEMA', 'MaxMillerOH', 'DaveYostOH', 'Miller_Congress'\\\n",
    "             'NewDemCoalition', 'DebbieLesko', 'ElissaSlotkin', 'PADEPSecretary', 'BriannaForCO', 'MikeStuartWV', 'justin4all2', 'voteSmitherman', 'CongressmanRaja', 'jessicalbenham'\\\n",
    "              'AlexPadilla4CA', 'RedState', 'DemSocialists', 'JaredEMoskowitz']\n",
    "journalists = [i for i in check_by_hand_ind3 if i not in (people + political)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame(news, columns = ['news_accounts']).to_csv('news_accounts.csv', index = False)\n",
    "pd.DataFrame(politics, columns = ['politics_accounts']).to_csv('govt_accounts.csv', index = False)\n",
    "pd.DataFrame(activists, columns = ['activists_accounts']).to_csv('activists_accounts.csv', index = False)\n",
    "pd.DataFrame(other, columns = ['other_accounts']).to_csv('other_accounts.csv', index = False)\n",
    "# These are accounts missing classification: these are individual verified accounts, at first glance: some are media, some are journalists \n",
    "# so, also media), but some are politicians, some are people...\n",
    "pd.DataFrame(check_by_hand_ind2, columns = ['check_by_hand_ind2']).to_csv('check_by_hand_ind2.csv', index = False)\n",
    "\n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "news_final = news + news_org_additional + journalists\n",
    "government_final = politics + government_additional + political\n",
    "people_final = people + activists + other"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1821, 119, 48)"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# De las verificadas mias y de las es media de mahrukh. Todo lo demas es gente\n",
    "len(news_final), len(government_final), len(people_final)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code', 'Continent Code', 'Continent',\n",
       "       'Country', 'City Code', 'Account Type', 'Added', 'Author', 'City',\n",
       "       'Entity Info', 'Expanded URLs', 'Full Name', 'Full Text', 'Gender',\n",
       "       'Hashtags', 'Impact', 'Impressions', 'Interest', 'Location Name',\n",
       "       'Media URLs', 'Mentioned Authors', 'Original Url', 'Professions',\n",
       "       'Resource Id', 'Short URLs', 'Thread Author', 'Thread Created Date',\n",
       "       'Thread Entry Type', 'Thread Id', 'Twitter Author ID',\n",
       "       'Twitter Followers', 'Twitter Following', 'Twitter Reply Count',\n",
       "       'Twitter Reply to', 'Twitter Retweet of', 'Twitter Retweets',\n",
       "       'Twitter Likes', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Reach (new)', 'Engagement Type', 'Region', 'Region Code',\n",
       "       'Weblog Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3.columns"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# parsing MK dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yv/9jkc42cj01gb_08dbbq9fcnw0000gn/T/ipykernel_67692/646333807.py:7: FutureWarning: In a future version of pandas all arguments of StringMethods.split except for the argument 'pat' will be keyword-only.\n",
      "  tweet_agent[['Date', 'Time']] = tweet_agent['DATE'].str.split(' ', 1, expand=True)\n"
     ]
    }
   ],
   "source": [
    "tweet = pd.read_csv('Data/Tweet.csv')\n",
    "agent = pd.read_csv('Data/Agent.csv')\n",
    "hashtag = pd.read_csv('Data/Hashtag.csv')\n",
    "url = pd.read_csv('Data/Url.csv')\n",
    "agent.rename(columns = {'Node Label' : 'Sender'}, inplace=True)\n",
    "tweet_agent = pd.merge(tweet, agent, on=['Sender'])\n",
    "tweet_agent[['Date', 'Time']] = tweet_agent['DATE'].str.split(' ', 1, expand=True)\n",
    "tweet_agent.drop(columns=['Language_y','Location','DATE'], inplace = True)\n",
    "tweet_agent.rename(columns={'Node ID_x' : 'TWEET_ID', \n",
    "                            'Node ID_y' : 'AGENT_ID', \n",
    "                            'Language_x' : 'LANGUAGE',\n",
    "                            'conversation_id' : 'CONVERSATION_ID',\n",
    "                            'Latitude' : 'LATITUDE',\n",
    "                            'Longitude' : 'LONGITUDE',\n",
    "                            'Sender' : 'SENDER',\n",
    "                            'Date' : 'DATE',\n",
    "                            'Time' : 'TIME'\n",
    "                            }, inplace=True)\n",
    "tweet_agent['IS_RETWEET'] = tweet_agent['IS_RETWEET'].fillna(0)\n",
    "tweet_agent['HAS_URL'] = tweet_agent['HAS_URL'].fillna(0)\n",
    "tweet_agent['IS_REPLY'] = tweet_agent['IS_REPLY'].fillna(0)\n",
    "tweet_agent['IS_IN_REPLY_TO'] = tweet_agent['IS_IN_REPLY_TO'].fillna(0)\n",
    "tweet_agent['IS_QUOTE'] = tweet_agent['IS_QUOTE'].fillna(0)\n",
    "tweet_agent['IS_GEOTAGGED'] = tweet_agent['IS_GEOTAGGED'].fillna(0)\n",
    "tweet_agent['IS_NEWS_AGENCY'] = tweet_agent['IS_NEWS_AGENCY'].fillna(0)\n",
    "tweets_data = tweet_agent[tweet_agent.columns.difference(['CONVERSATION_ID','IS_GEOTAGGED','LATITUDE','LONGITUDE','AGENT_ID'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.7729956985588957"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.MESSAGE.duplicated().sum() / len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Query Id', 'Query Name', 'Date', 'Title', 'Url', 'Domain', 'Sentiment',\n",
       "       'Page Type', 'Language', 'Country Code', 'Continent Code', 'Continent',\n",
       "       'Country', 'City Code', 'Account Type', 'Added', 'Author', 'City',\n",
       "       'Entity Info', 'Expanded URLs', 'Full Name', 'Full Text', 'Gender',\n",
       "       'Hashtags', 'Impact', 'Impressions', 'Interest', 'Location Name',\n",
       "       'Media URLs', 'Mentioned Authors', 'Original Url', 'Professions',\n",
       "       'Resource Id', 'Short URLs', 'Thread Author', 'Thread Created Date',\n",
       "       'Thread Entry Type', 'Thread Id', 'Twitter Author ID',\n",
       "       'Twitter Followers', 'Twitter Following', 'Twitter Reply Count',\n",
       "       'Twitter Reply to', 'Twitter Retweet of', 'Twitter Retweets',\n",
       "       'Twitter Likes', 'Twitter Tweets', 'Twitter Verified', 'Updated',\n",
       "       'Reach (new)', 'Engagement Type', 'Region', 'Region Code',\n",
       "       'Weblog Title'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_from_dataset3 = ['Query Id', 'Query Name', 'Url', 'Domain', 'Page Type', 'Language', 'Continent Code', 'Continent',\n",
    "       'Country', 'City Code', 'Added'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_to_merge = ['Account Type', 'Sentiment', ]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rename\n",
    "{'Author' :  'SENDER'}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tinfoilted1        195\n",
       "DonovanLawTampa    191\n",
       "Cat_In_A_Bag230    142\n",
       "argo_times          77\n",
       "WKBN                69\n",
       "                  ... \n",
       "slimhiney            1\n",
       "TheBigJack68         1\n",
       "MediaEqualizer       1\n",
       "D_E_Wiley            1\n",
       "b_lott24             1\n",
       "Name: Author, Length: 39780, dtype: int64"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_3['Author'].value_counts(dropna = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['DATE', 'HAS_URL', 'IS_IN_REPLY_TO', 'IS_NEWS_AGENCY', 'IS_QUOTE',\n",
       "       'IS_REPLY', 'IS_RETWEET', 'IS_VERIFIED', 'LANGUAGE', 'LOCATION',\n",
       "       'MESSAGE', 'NUMBER_FOLLOWERS', 'RETWEET_COUNT', 'SENDER', 'TIME',\n",
       "       'TWEET_COUNT', 'TWEET_ID'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                     USA\n",
       "1                     USA\n",
       "2                     USA\n",
       "3                     USA\n",
       "4            New York, NY\n",
       "               ...       \n",
       "123352                NaN\n",
       "123406    (City of Trees)\n",
       "123412                NaN\n",
       "123413                NaN\n",
       "123431                NaN\n",
       "Name: LOCATION, Length: 28023, dtype: object"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweets_data.LOCATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/yv/9jkc42cj01gb_08dbbq9fcnw0000gn/T/ipykernel_67692/161562069.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  tweets_data.drop_duplicates(subset = ['MESSAGE'], inplace = True)\n"
     ]
    }
   ],
   "source": [
    "tweets_data.drop_duplicates(subset = ['MESSAGE'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "28023"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tweets_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Intro_AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "3eb23708133211dcd341a8aa35b90f924296bf92f5e22e78650e8d6fafcfea05"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
